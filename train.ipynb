{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(Minified) Melanoma Classification Kaggle - TF TPUs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOQsXODNgg7D",
        "colab_type": "text"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u395mvGtfvL7",
        "colab_type": "code",
        "outputId": "6e04a63e-ca1c-4de2-f9ef-1298e0127986",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#@title Enter Kaggle Credentials\n",
        "import os\n",
        "from getpass import getpass\n",
        "os.environ['KAGGLE_USERNAME'] = 'ranik40' #@param {type:\"string\"}\n",
        "print('Enter your kaggle key')\n",
        "os.environ['KAGGLE_KEY'] = getpass()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter your kaggle key\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrbZ9Bynf2Bo",
        "colab_type": "code",
        "outputId": "7d3c6eff-f31d-4412-8a90-b8255a625a89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "!pip uninstall -y kaggle\n",
        "!pip install -qq -U \"kaggle\" \"tensorflow-model-optimization\" \"gcsfs\" \"focal-loss\""
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping kaggle as it is not installed.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 61kB 2.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 174kB 8.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 296kB 10.1MB/s \n",
            "\u001b[?25h  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GESMMQFf86o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxKKD3QCltRN",
        "colab_type": "code",
        "outputId": "4b4dd043-709c-480a-b7dd-b08668d7dbcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "TPU_NAME = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "TPU_NAME"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'grpc://10.49.17.50:8470'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BKcykNLf98x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVA9vNZ3f8SF",
        "colab_type": "text"
      },
      "source": [
        "# tensorflow/models Image Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ve-2pzu6f6LH",
        "colab_type": "code",
        "outputId": "c66f894d-cfb6-4686-e28a-0b3d766cdbab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "source": [
        "!rm -rf models\n",
        "!git clone https://github.com/tensorflow/models.git -b v2.2.0"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 46, done.\u001b[K\n",
            "remote: Counting objects:   2% (1/46)\u001b[K\rremote: Counting objects:   4% (2/46)\u001b[K\rremote: Counting objects:   6% (3/46)\u001b[K\rremote: Counting objects:   8% (4/46)\u001b[K\rremote: Counting objects:  10% (5/46)\u001b[K\rremote: Counting objects:  13% (6/46)\u001b[K\rremote: Counting objects:  15% (7/46)\u001b[K\rremote: Counting objects:  17% (8/46)\u001b[K\rremote: Counting objects:  19% (9/46)\u001b[K\rremote: Counting objects:  21% (10/46)\u001b[K\rremote: Counting objects:  23% (11/46)\u001b[K\rremote: Counting objects:  26% (12/46)\u001b[K\rremote: Counting objects:  28% (13/46)\u001b[K\rremote: Counting objects:  30% (14/46)\u001b[K\rremote: Counting objects:  32% (15/46)\u001b[K\rremote: Counting objects:  34% (16/46)\u001b[K\rremote: Counting objects:  36% (17/46)\u001b[K\rremote: Counting objects:  39% (18/46)\u001b[K\rremote: Counting objects:  41% (19/46)\u001b[K\rremote: Counting objects:  43% (20/46)\u001b[K\rremote: Counting objects:  45% (21/46)\u001b[K\rremote: Counting objects:  47% (22/46)\u001b[K\rremote: Counting objects:  50% (23/46)\u001b[K\rremote: Counting objects:  52% (24/46)\u001b[K\rremote: Counting objects:  54% (25/46)\u001b[K\rremote: Counting objects:  56% (26/46)\u001b[K\rremote: Counting objects:  58% (27/46)\u001b[K\rremote: Counting objects:  60% (28/46)\u001b[K\rremote: Counting objects:  63% (29/46)\u001b[K\rremote: Counting objects:  65% (30/46)\u001b[K\rremote: Counting objects:  67% (31/46)\u001b[K\rremote: Counting objects:  69% (32/46)\u001b[K\rremote: Counting objects:  71% (33/46)\u001b[K\rremote: Counting objects:  73% (34/46)\u001b[K\rremote: Counting objects:  76% (35/46)\u001b[K\rremote: Counting objects:  78% (36/46)\u001b[K\rremote: Counting objects:  80% (37/46)\u001b[K\rremote: Counting objects:  82% (38/46)\u001b[K\rremote: Counting objects:  84% (39/46)\u001b[K\rremote: Counting objects:  86% (40/46)\u001b[K\rremote: Counting objects:  89% (41/46)\u001b[K\rremote: Counting objects:  91% (42/46)\u001b[K\rremote: Counting objects:  93% (43/46)\u001b[K\rremote: Counting objects:  95% (44/46)\u001b[K\rremote: Counting objects:  97% (45/46)\u001b[K\rremote: Counting objects: 100% (46/46)\u001b[K\rremote: Counting objects: 100% (46/46), done.\u001b[K\n",
            "remote: Compressing objects: 100% (46/46), done.\u001b[K\n",
            "remote: Total 36784 (delta 23), reused 22 (delta 0), pack-reused 36738\u001b[K\n",
            "Receiving objects: 100% (36784/36784), 520.38 MiB | 47.42 MiB/s, done.\n",
            "Resolving deltas: 100% (24519/24519), done.\n",
            "Note: checking out '93490036e00f37ecbe6693b9ff4ae488bb8e9270'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvAYZpDNGI3c",
        "colab_type": "text"
      },
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gbofl06wHraN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "342024ae-9376-4357-c4d3-0f4da27348d8"
      },
      "source": [
        "# Get train & validation \n",
        "!gsutil cp gs://recursion-kaggle/melanoma/stratified_ex/fold0/idx_train.csv .\n",
        "!gsutil cp gs://recursion-kaggle/melanoma/stratified_ex/fold0/idx_validation.csv ."
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://recursion-kaggle/melanoma/stratified_ex/fold0/idx_train.csv...\n",
            "/ [0 files][    0.0 B/  1.5 MiB]                                                \r/ [1 files][  1.5 MiB/  1.5 MiB]                                                \r\n",
            "Operation completed over 1 objects/1.5 MiB.                                      \n",
            "Copying gs://recursion-kaggle/melanoma/stratified_ex/fold0/idx_validation.csv...\n",
            "/ [1 files][392.7 KiB/392.7 KiB]                                                \n",
            "Operation completed over 1 objects/392.7 KiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEfELiMgDa3E",
        "colab_type": "text"
      },
      "source": [
        "## Compute initial bias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXj3uAKjmmaJ",
        "colab_type": "code",
        "outputId": "5254e81f-59fd-408e-c87c-8bb0493a3684",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "train = pd.read_csv('idx_train.csv')\n",
        "train.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>patient_id</th>\n",
              "      <th>target</th>\n",
              "      <th>source</th>\n",
              "      <th>sex</th>\n",
              "      <th>age_approx</th>\n",
              "      <th>anatom_site_general_challenge</th>\n",
              "      <th>stratify_group</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ISIC_2637011</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>45</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ISIC_0015719</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ISIC_0052212</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ISIC_0068279</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>45</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ISIC_0074268</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>55</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     image_name  patient_id  ...  stratify_group  fold\n",
              "0  ISIC_2637011           0  ...              32     2\n",
              "1  ISIC_0015719           1  ...              28     1\n",
              "2  ISIC_0052212           2  ...               8     1\n",
              "3  ISIC_0068279           3  ...               2     4\n",
              "4  ISIC_0074268           4  ...              28     3\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kty-NQs1pcDv",
        "colab_type": "code",
        "outputId": "d290e0cc-6723-4089-9192-27c780900d1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "valid = pd.read_csv('idx_validation.csv')\n",
        "valid.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>patient_id</th>\n",
              "      <th>target</th>\n",
              "      <th>source</th>\n",
              "      <th>sex</th>\n",
              "      <th>age_approx</th>\n",
              "      <th>anatom_site_general_challenge</th>\n",
              "      <th>stratify_group</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ISIC_0075914</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>3</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ISIC_0076742</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>75</td>\n",
              "      <td>1</td>\n",
              "      <td>58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ISIC_0079038</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>70</td>\n",
              "      <td>3</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ISIC_0080512</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>75</td>\n",
              "      <td>3</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ISIC_0083035</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     image_name  patient_id  ...  stratify_group  fold\n",
              "0  ISIC_0075914           8  ...              50     0\n",
              "1  ISIC_0076742          11  ...              58     0\n",
              "2  ISIC_0079038          16  ...              50     0\n",
              "3  ISIC_0080512          17  ...              50     0\n",
              "4  ISIC_0083035          24  ...              50     0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgkcmjNlm6wy",
        "colab_type": "code",
        "outputId": "34cb26de-5bfc-4de3-e6bb-cc069c2bd0e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train.shape[0], valid.shape[0]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46648, 11809)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XM52L_jomrmN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "97355c28-e751-41cd-9af6-3843fdb19c28"
      },
      "source": [
        "neg = train[train['target'] == 0].shape[0]\n",
        "pos = train[train['target'] == 1].shape[0]\n",
        "\n",
        "initial_bias = np.log([pos/neg])\n",
        "initial_bias"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-2.3498501])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hEcd-xWq3PP",
        "colab_type": "text"
      },
      "source": [
        "# Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42_HDJ3AJO0P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append(\"models\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6LnP6K7JePN",
        "colab_type": "text"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2w0b8PXPO-is",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Dataset\n",
        "import os\n",
        "# import numpy as np\n",
        "from typing import Any, List, Optional, Tuple, Mapping, Union\n",
        "from absl import logging\n",
        "from dataclasses import dataclass\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "\n",
        "from official.modeling.hyperparams import base_config\n",
        "from official.vision.image_classification import augment\n",
        "from official.vision.image_classification import preprocessing\n",
        "from official.vision.image_classification import dataset_factory\n",
        "\n",
        "\n",
        "class DatasetBuilder(dataset_factory.DatasetBuilder):\n",
        "  def load_records(self) -> tf.data.Dataset:\n",
        "    \"\"\"Return a dataset loading files with TFRecords.\"\"\"\n",
        "    logging.info('Using TFRecords to load data.')\n",
        "\n",
        "    if self.config.filenames is None:\n",
        "      if self.config.data_dir is None:\n",
        "        raise ValueError('Dataset must specify a path for the data files.')\n",
        "\n",
        "      file_pattern = os.path.join(self.config.data_dir,\n",
        "                                  '{}*'.format(self.config.split))\n",
        "      \n",
        "      if self.config.split in ['train', 'validation']:\n",
        "        shuffle = True\n",
        "      else:\n",
        "        shuffle = False\n",
        "\n",
        "      dataset = tf.data.Dataset.list_files(file_pattern, shuffle=shuffle)\n",
        "    else:\n",
        "      dataset = tf.data.Dataset.from_tensor_slices(self.config.filenames)\n",
        "      if self.is_training:\n",
        "        # Shuffle the input files.\n",
        "        dataset.shuffle(buffer_size=self.config.file_shuffle_buffer_size)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "  def pipeline(self,\n",
        "               dataset: tf.data.Dataset,\n",
        "               input_context: tf.distribute.InputContext = None\n",
        "              ) -> tf.data.Dataset:\n",
        "    \"\"\"Build a pipeline fetching, shuffling, and preprocessing the dataset.\"\"\"\n",
        "    if input_context and input_context.num_input_pipelines > 1:\n",
        "      dataset = dataset.shard(input_context.num_input_pipelines,\n",
        "                              input_context.input_pipeline_id)\n",
        "\n",
        "    if self.is_training and not self.config.cache:\n",
        "      dataset = dataset.repeat()\n",
        "\n",
        "    if self.config.builder == 'records':\n",
        "      # Read the data from disk in parallel\n",
        "      buffer_size = 8 * 1024 * 1024  # Use 8 MiB per file\n",
        "      dataset = dataset.interleave(\n",
        "          lambda name: tf.data.TFRecordDataset(name, buffer_size=buffer_size),\n",
        "          cycle_length=16,\n",
        "          num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    \n",
        "    dataset = dataset.prefetch(self.global_batch_size)\n",
        "\n",
        "    if self.config.cache:\n",
        "      dataset = dataset.cache()\n",
        "\n",
        "    if self.is_training:\n",
        "      dataset = dataset.shuffle(self.config.shuffle_buffer_size)\n",
        "      dataset = dataset.repeat()\n",
        "\n",
        "    # Parse, pre-process, and batch the data in parallel\n",
        "    if self.config.builder == 'records':\n",
        "      if self.config.split in ['train', 'validation']:\n",
        "        preprocess = self.parse_record\n",
        "      else:\n",
        "        preprocess = self.parse_test_record\n",
        "    else:\n",
        "      preprocess = self.preprocess\n",
        "\n",
        "    dataset = dataset.map(preprocess,\n",
        "                          num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    # Dataset balancing utilities\n",
        "    @tf.function\n",
        "    def class_func(image, label):\n",
        "      return label\n",
        "\n",
        "    @tf.function\n",
        "    def drop_extra_label(extra_label, image_and_label):\n",
        "      return image_and_label\n",
        "\n",
        "    # if self.is_training:\n",
        "    #   # Balance the dataset\n",
        "    #   TARGET_DIST = [0.5, 0.5]\n",
        "    #   INITIAL_DIST = [0.95, 0.05]\n",
        "\n",
        "    #   resampler = tf.data.experimental.rejection_resample(\n",
        "    #       class_func, \n",
        "    #       target_dist=TARGET_DIST,\n",
        "    #       # seed=42,\n",
        "    #       initial_dist=INITIAL_DIST\n",
        "    #   )\n",
        "    #   dataset = dataset.apply(resampler)\n",
        "\n",
        "    dataset = dataset.batch(self.batch_size, drop_remainder=self.is_training)\n",
        "    \n",
        "    # if self.is_training:\n",
        "    #   # The resampler returns creates (class, example) pairs from the output of the class_func. \n",
        "    #   # In this case, the example was already a (feature, label) pair, \n",
        "    #   # so use map to drop the extra copy of the labels\n",
        "    #   dataset = dataset.map(\n",
        "    #       drop_extra_label,\n",
        "    #       num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        "    #   )\n",
        "\n",
        "    if self.config.split in ['test']:\n",
        "      options = tf.data.Options()\n",
        "      options.experimental_optimization.parallel_batch = True\n",
        "      options.experimental_optimization.map_fusion = True\n",
        "      # Note: Disabled map vectorization for balanced sampling\n",
        "      # options.experimental_optimization.map_vectorization.enabled = True\n",
        "      options.experimental_optimization.map_parallelization = True\n",
        "      dataset = dataset.with_options(options)\n",
        "      \n",
        "    elif self.is_training and self.config.deterministic_train is not None:\n",
        "      options = tf.data.Options()\n",
        "      options.experimental_deterministic = self.config.deterministic_train\n",
        "      options.experimental_slack = self.config.use_slack\n",
        "      options.experimental_optimization.parallel_batch = True\n",
        "      options.experimental_optimization.map_fusion = True\n",
        "      # Note: Disabled map vectorization for balanced sampling\n",
        "      # options.experimental_optimization.map_vectorization.enabled = True\n",
        "      options.experimental_optimization.map_parallelization = True\n",
        "      dataset = dataset.with_options(options)\n",
        "\n",
        "    # Prefetch overlaps in-feed with training\n",
        "    # Note: autotune here is not recommended, as this can lead to memory leaks.\n",
        "    # Instead, use a constant prefetch size like the the number of devices.\n",
        "    dataset = dataset.prefetch(self.config.num_devices)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "  @tf.function\n",
        "  def parse_record(self, record: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor]:\n",
        "    \"\"\"Parse an ImageNet record from a serialized string Tensor.\"\"\"\n",
        "    keys_to_features = {\n",
        "        'image':\n",
        "            tf.io.FixedLenFeature((), tf.string, ''),\n",
        "        # \"age_approx\": tf.io.FixedLenFeature([], tf.int64, -1),  \n",
        "        # \"sex\": tf.io.FixedLenFeature([], tf.int64, -1),  \n",
        "        'target':\n",
        "            tf.io.FixedLenFeature([], tf.int64, -1)\n",
        "    }\n",
        "    \n",
        "    parsed = tf.io.parse_single_example(record, keys_to_features)\n",
        "\n",
        "    # age = tf.cast(parsed['age_approx'], tf.float32) / 30.\n",
        "    # sex = tf.cast(parsed['sex'], tf.float32)\n",
        "\n",
        "    # label = tf.reshape(parsed['target'], shape=[1])\n",
        "    label = parsed['target']\n",
        "    label = tf.cast(label, dtype=tf.int32)\n",
        "\n",
        "    # image_bytes = tf.reshape(parsed['image'], shape=[])\n",
        "    image_bytes = parsed['image']\n",
        "    image, label = self.preprocess(image_bytes, label)\n",
        "\n",
        "    return image, label\n",
        "    # return (image, tf.stack([age,sex])), label\n",
        "\n",
        "  def parse_test_record(self, record: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor]:\n",
        "    \"\"\"Parse an ImageNet record from a serialized string Tensor.\"\"\"\n",
        "    keys_to_features = {\n",
        "        'image':\n",
        "            tf.io.FixedLenFeature((), tf.string, ''),\n",
        "        # \"age_approx\": tf.io.FixedLenFeature([], tf.int64, -1),  \n",
        "        # \"sex\": tf.io.FixedLenFeature([], tf.int64, -1),  \n",
        "        'target':\n",
        "            tf.io.FixedLenFeature([], tf.int64, -1),\n",
        "        \"image_name\": \n",
        "            tf.io.FixedLenFeature((), tf.string)\n",
        "    }\n",
        "    \n",
        "    parsed = tf.io.parse_single_example(record, keys_to_features)\n",
        "\n",
        "    # age = tf.cast(parsed['age_approx'], tf.float32) / 30.\n",
        "    # sex = tf.cast(parsed['sex'], tf.float32)\n",
        "\n",
        "    # label = tf.reshape(parsed['target'], shape=[1])\n",
        "    label = parsed['target']\n",
        "    label = tf.cast(label, dtype=tf.int32)\n",
        "\n",
        "    # image_bytes = tf.reshape(parsed['image'], shape=[])\n",
        "    image_bytes = parsed['image']\n",
        "    image, _ = self.preprocess(image_bytes, label)\n",
        "\n",
        "    image_name = parsed['image_name']\n",
        "\n",
        "    return image, image_name\n",
        "    # return (image, tf.stack([age,sex])), image_name\n",
        "\n",
        "dataset_factory.DatasetBuilder = DatasetBuilder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HRcRrY3c-6u",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title EfficientNet Model\n",
        "import math\n",
        "import os\n",
        "from typing import Any, Dict, Optional, Text, Tuple\n",
        "\n",
        "from absl import logging\n",
        "import tensorflow as tf\n",
        "\n",
        "from official.vision.image_classification.efficientnet import efficientnet_model\n",
        "\n",
        "class ModelConfig(efficientnet_model.ModelConfig):\n",
        "  num_classes: int = 2\n",
        "\n",
        "\n",
        "class EfficientNet(tf.keras.Model):\n",
        "  \"\"\"Wrapper class for an EfficientNet Keras model.\n",
        "  Contains helper methods to build, manage, and save metadata about the model.\n",
        "  \"\"\"\n",
        "  def __init__(self,\n",
        "               config: ModelConfig = None,\n",
        "               overrides: Dict[Text, Any] = None):\n",
        "    \"\"\"Create an EfficientNet model.\n",
        "    Args:\n",
        "      config: (optional) the main model parameters to create the model\n",
        "      overrides: (optional) a dict containing keys that can override\n",
        "                 config\n",
        "    \"\"\"\n",
        "    overrides = overrides or {}\n",
        "    config = config or ModelConfig()\n",
        "\n",
        "    self.config = config.replace(**overrides)\n",
        "\n",
        "    input_channels = self.config.input_channels\n",
        "    model_name = self.config.model_name\n",
        "    input_shape = (None, None, input_channels)  # Should handle any size image\n",
        "\n",
        "    image_input = tf.keras.layers.Input(shape=input_shape)\n",
        "\n",
        "    output = efficientnet_model.efficientnet(image_input, self.config)\n",
        "\n",
        "    # Cast to float32 in case we have a different model dtype\n",
        "    # output = tf.cast(output, tf.float32)\n",
        "\n",
        "    logging.info('Building model %s with params %s',\n",
        "                 model_name,\n",
        "                 self.config)\n",
        "\n",
        "    super(EfficientNet, self).__init__(\n",
        "        inputs=image_input, \n",
        "        outputs=output, \n",
        "        name=model_name)\n",
        "\n",
        "  @classmethod\n",
        "  def from_name(cls,\n",
        "                model_name: Text,\n",
        "                model_weights_path: Text = None,\n",
        "                copy_to_local: bool = False,\n",
        "                overrides: Dict[Text, Any] = None):\n",
        "    \"\"\"Construct an EfficientNet model from a predefined model name\"\"\"\n",
        "    model_configs = dict(efficientnet_model.MODEL_CONFIGS)\n",
        "    overrides = dict(overrides) if overrides else {}\n",
        "\n",
        "    # One can define their own custom models if necessary\n",
        "    model_configs.update(overrides.pop('model_config', {}))\n",
        "\n",
        "    if model_name not in model_configs:\n",
        "      raise ValueError('Unknown model name {}'.format(model_name))\n",
        "\n",
        "    config = model_configs[model_name]\n",
        "\n",
        "    model = cls(config=config, overrides=overrides)\n",
        "\n",
        "    # Pop the classification layer\n",
        "    model = tf.keras.Model(model.inputs, model.layers[-3].output)\n",
        "\n",
        "    if model_weights_path:\n",
        "      if copy_to_local:\n",
        "        tmp_file = os.path.join('/tmp', model_name + '.h5')\n",
        "        model_weights_file = os.path.join(model_weights_path, 'model.h5')\n",
        "        tf.io.gfile.copy(model_weights_file, tmp_file, overwrite=True)\n",
        "        model_weights_path = tmp_file\n",
        "\n",
        "      loaded_model = tf.keras.models.load_model(model_weights_path, compile=False)\n",
        "      model.set_weights(loaded_model.get_weights())\n",
        "    \n",
        "    initial_bias = -2.3498501\n",
        "    output_bias = tf.keras.initializers.Constant(initial_bias)\n",
        "\n",
        "    output = model.output\n",
        "\n",
        "    x = tf.keras.layers.Dense(\n",
        "      # config.num_classes,\n",
        "      1,\n",
        "      kernel_initializer=efficientnet_model.DENSE_KERNEL_INITIALIZER,\n",
        "      bias_initializer=output_bias,\n",
        "      # kernel_regularizer=tf.keras.regularizers.l2(config.weight_decay),\n",
        "      # bias_regularizer=tf.keras.regularizers.l2(config.weight_decay),\n",
        "      name='logits')(output)\n",
        "\n",
        "    x = tf.keras.layers.Activation('sigmoid', name='probs')(x)\n",
        "\n",
        "    # Cast to float32 in case we have a different model dtype\n",
        "    x = tf.cast(x, tf.float32)\n",
        "    model = tf.keras.Model(inputs=model.inputs, outputs=x)\n",
        "    return model\n",
        "\n",
        "efficientnet_model.EfficientNet = EfficientNet\n",
        "efficientnet_model.ModelConfig = ModelConfig\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ws3pH2uEwPcr",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Callbacks\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "# from __future__ import google_type_annotations\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "from absl import logging\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from typing import Any, List, MutableMapping\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "from official.utils.misc import keras_utils\n",
        "from official.vision.image_classification import callbacks\n",
        "\n",
        "\n",
        "def get_callbacks(validation_dataset,\n",
        "                  num_validation_samples,\n",
        "                  model_checkpoint: bool = True,\n",
        "                  include_tensorboard: bool = True,\n",
        "                  time_history: bool = True,\n",
        "                  track_lr: bool = True,\n",
        "                  write_model_weights: bool = True,\n",
        "                  initial_step: int = 0,\n",
        "                  batch_size: int = 0,\n",
        "                  log_steps: int = 0,\n",
        "                  model_dir: str = None) -> List[tf.keras.callbacks.Callback]:\n",
        "  \"\"\"Get all callbacks.\"\"\"\n",
        "  model_dir = model_dir or ''\n",
        "  callbacks = []\n",
        "\n",
        "  if model_checkpoint:\n",
        "    # ckpt_full_path = os.path.join(model_dir, 'model.ckpt-{epoch:04d}')\n",
        "    ckpt_full_path = os.path.join(model_dir, 'model.ckpt')\n",
        "    callbacks.append(\n",
        "        ModelCheckpoint(\n",
        "            validation_dataset,\n",
        "            num_validation_samples,\n",
        "            ckpt_full_path, \n",
        "            monitor='val_auc',\n",
        "            mode='max',\n",
        "            # save_freq=250,\n",
        "            save_best_only=True,\n",
        "            save_weights_only=True, verbose=1))\n",
        "  if include_tensorboard:\n",
        "    callbacks.append(\n",
        "        CustomTensorBoard(\n",
        "            log_dir=model_dir,\n",
        "            track_lr=track_lr,\n",
        "            initial_step=initial_step,\n",
        "            write_images=write_model_weights))\n",
        "    \n",
        "  # reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "  #     monitor='val_auc', factor=0.8, patience=1, verbose=1, mode='max',\n",
        "  #     min_delta=0.0001, cooldown=0, min_lr=1e-8, **kwargs\n",
        "  # )\n",
        "  return callbacks\n",
        "\n",
        "\n",
        "class ModelCheckpoint(tf.keras.callbacks.ModelCheckpoint):\n",
        "    def __init__(self, validation_dataset, num_validation_samples, *args, **kwargs):\n",
        "        super(ModelCheckpoint, self).__init__(*args, **kwargs)\n",
        "        self.validation_dataset = validation_dataset\n",
        "        labels_dataset = self.validation_dataset.map(lambda image, label: label).unbatch()\n",
        "        NUM_VALIDATION_IMAGES = num_validation_samples\n",
        "        self.y_true = next(iter(labels_dataset.batch(NUM_VALIDATION_IMAGES))).numpy()\n",
        "        \n",
        "    def _save_model(self, epoch, logs):\n",
        "        y_pred = self.model.predict(self.validation_dataset, verbose=0)\n",
        "        current = roc_auc_score(self.y_true, y_pred)\n",
        "        # print(\"ROC-AUC - epoch: {:d} - score: {:.6f}\\n\".format(epoch+1, score))\n",
        "\n",
        "        if isinstance(self.save_freq,\n",
        "                      int) or self.epochs_since_last_save >= self.period:\n",
        "          self.epochs_since_last_save = 0\n",
        "          filepath = self._get_file_path(epoch, logs)\n",
        "\n",
        "          try:\n",
        "            if self.save_best_only:\n",
        "              if current is None:\n",
        "                logging.warning('Can save best model only with %s available, '\n",
        "                                'skipping.', self.monitor)\n",
        "              else:\n",
        "                if self.monitor_op(current, self.best):\n",
        "                  if self.verbose > 0:\n",
        "                    print('\\nEpoch %05d: %s improved from %0.5f to %0.5f,'\n",
        "                          ' saving model to %s' % (epoch + 1, self.monitor,\n",
        "                                                  self.best, current, filepath))\n",
        "                  self.best = current\n",
        "                  if self.save_weights_only:\n",
        "                    self.model.save_weights(filepath, overwrite=True)\n",
        "                  else:\n",
        "                    self.model.save(filepath, overwrite=True)\n",
        "                else:\n",
        "                  if self.verbose > 0:\n",
        "                    print('\\nEpoch %05d: %s did not improve from %0.5f (val_auc = %0.5f)' %\n",
        "                          (epoch + 1, self.monitor, self.best, current))\n",
        "            else:\n",
        "              if self.verbose > 0:\n",
        "                print('\\nEpoch %05d: saving model to %s' % (epoch + 1, filepath))\n",
        "              if self.save_weights_only:\n",
        "                self.model.save_weights(filepath, overwrite=True)\n",
        "              else:\n",
        "                self.model.save(filepath, overwrite=True)\n",
        "\n",
        "            self._maybe_remove_file()\n",
        "          except IOError as e:\n",
        "            # `e.errno` appears to be `None` so checking the content of `e.args[0]`.\n",
        "            if 'is a directory' in six.ensure_str(e.args[0]):\n",
        "              raise IOError('Please specify a non-directory filepath for '\n",
        "                            'ModelCheckpoint. Filepath used is an existing '\n",
        "                            'directory: {}'.format(filepath))\n",
        "              \n",
        "callbacks.get_callbacks = get_callbacks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DglQn8C4EKrT",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Classifier Trainer\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "\n",
        "import pprint\n",
        "from typing import Any, Tuple, Text, Optional, Mapping\n",
        "\n",
        "from absl import app\n",
        "from absl import flags\n",
        "from absl import logging\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from focal_loss import BinaryFocalLoss\n",
        "\n",
        "from official.vision.image_classification.classifier_trainer import *\n",
        "from official.vision.image_classification.classifier_trainer import (\n",
        "    _get_params_from_flags, _get_dataset_builders\n",
        ")\n",
        "\n",
        "from official.vision.image_classification import classifier_trainer\n",
        "\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "\n",
        "class AUC(tf.keras.metrics.AUC):\n",
        "  def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "    y_pred = K.sigmoid(y_pred)\n",
        "    return super(AUC, self).update_state(y_true, y_pred, sample_weight)\n",
        "\n",
        "\n",
        "\n",
        "def _get_metrics(one_hot: bool) -> Mapping[Text, Any]:\n",
        "  \"\"\"Get a dict of available metrics to track.\"\"\"\n",
        "  if one_hot:\n",
        "    return {\n",
        "        'auc': tf.keras.metrics.AUC(name='auc'),\n",
        "        # 'auc': AUC(name='auc'),\n",
        "    }\n",
        "  else:\n",
        "    return {\n",
        "        'auc': tf.keras.metrics.AUC(name='auc'),\n",
        "        # 'auc': AUC(name='auc'),\n",
        "    }\n",
        "\n",
        "def train_and_eval(\n",
        "    params: base_configs.ExperimentConfig,\n",
        "    strategy_override: tf.distribute.Strategy) -> Mapping[str, Any]:\n",
        "  \"\"\"Runs the train and eval path using compile/fit.\"\"\"\n",
        "  logging.info('Running train and eval.')\n",
        "\n",
        "  # Note: for TPUs, strategy and scope should be created before the dataset\n",
        "  strategy = strategy_override or distribution_utils.get_distribution_strategy(\n",
        "      distribution_strategy=params.runtime.distribution_strategy,\n",
        "      all_reduce_alg=params.runtime.all_reduce_alg,\n",
        "      num_gpus=params.runtime.num_gpus,\n",
        "      tpu_address=params.runtime.tpu)\n",
        "\n",
        "  strategy_scope = distribution_utils.get_strategy_scope(strategy)\n",
        "\n",
        "  logging.info('Detected %d devices.',\n",
        "               strategy.num_replicas_in_sync if strategy else 1)\n",
        "\n",
        "  label_smoothing = params.model.loss.label_smoothing\n",
        "  one_hot = label_smoothing and label_smoothing > 0\n",
        "\n",
        "  builders = _get_dataset_builders(params, strategy, one_hot)\n",
        "  datasets = [builder.build() if builder else None for builder in builders]\n",
        "\n",
        "  # Unpack datasets and builders based on train/val/test splits\n",
        "  train_builder, validation_builder = builders  # pylint: disable=unbalanced-tuple-unpacking\n",
        "  train_dataset, validation_dataset = datasets\n",
        "\n",
        "  train_epochs = params.train.epochs\n",
        "  train_steps = params.train.steps or train_builder.num_steps\n",
        "  validation_steps = params.evaluation.steps or validation_builder.num_steps\n",
        "\n",
        "  initialize(params, train_builder)\n",
        "\n",
        "  logging.info('Global batch size: %d', train_builder.global_batch_size)\n",
        "\n",
        "  with strategy_scope:\n",
        "    model_params = params.model.model_params.as_dict()\n",
        "    model = get_models()[params.model.name](**model_params)\n",
        "    learning_rate = optimizer_factory.build_learning_rate(\n",
        "        params=params.model.learning_rate,\n",
        "        batch_size=train_builder.global_batch_size,\n",
        "        train_steps=train_steps)\n",
        "    optimizer = optimizer_factory.build_optimizer(\n",
        "        optimizer_name=params.model.optimizer.name,\n",
        "        base_learning_rate=learning_rate,\n",
        "        params=params.model.optimizer.as_dict())\n",
        "\n",
        "    metrics_map = _get_metrics(one_hot)\n",
        "    metrics = [metrics_map[metric] for metric in params.train.metrics]\n",
        "\n",
        "    # if one_hot:\n",
        "    #   loss_obj = losses.CategoricalCrossentropy(\n",
        "    #       label_smoothing=params.model.loss.label_smoothing)\n",
        "    # else:\n",
        "    #   loss_obj = losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "    # if one_hot:\n",
        "    #   loss_obj = losses.BinaryCrossentropy(\n",
        "    #       label_smoothing=params.model.loss.label_smoothing)\n",
        "    # else:\n",
        "    #   loss_obj = losses.BinaryCrossentropy()\n",
        "\n",
        "    loss_obj = BinaryFocalLoss(\n",
        "          pos_weight=1,\n",
        "          gamma=2,\n",
        "          label_smoothing=params.model.loss.label_smoothing\n",
        "    )\n",
        "\n",
        "    # loss_obj = tfr.keras.losses.get(\n",
        "    #     tfr.losses.RankingLossKey.SIGMOID_CROSS_ENTROPY_LOSS)\n",
        "\n",
        "    # loss_obj = losses.SurrogateLoss()\n",
        "    # loss_obj = losses.RankBoostLoss()\n",
        "    # loss_obj = losses.ROCAUCLoss()\n",
        "\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss=loss_obj,\n",
        "                  metrics=metrics)\n",
        "    \n",
        "    initial_epoch = 0\n",
        "    if params.train.resume_checkpoint:\n",
        "      initial_epoch = resume_from_checkpoint(model=model,\n",
        "                                             model_dir=params.model_dir,\n",
        "                                             train_steps=train_steps)\n",
        "\n",
        "  serialize_config(params=params, model_dir=params.model_dir)\n",
        "\n",
        "  callbacks = custom_callbacks.get_callbacks(\n",
        "      validation_dataset,\n",
        "      params.validation_dataset.num_examples,\n",
        "      model_checkpoint=params.train.callbacks.enable_checkpoint_and_export,\n",
        "      include_tensorboard=params.train.callbacks.enable_tensorboard,\n",
        "      time_history=params.train.callbacks.enable_time_history,\n",
        "      track_lr=params.train.tensorboard.track_lr,\n",
        "      write_model_weights=params.train.tensorboard.write_model_weights,\n",
        "      initial_step=initial_epoch * train_steps,\n",
        "      batch_size=train_builder.global_batch_size,\n",
        "      log_steps=params.train.time_history.log_steps,\n",
        "      model_dir=params.model_dir)\n",
        "\n",
        "  if params.evaluation.skip_eval:\n",
        "    validation_kwargs = {}\n",
        "  else:\n",
        "    validation_kwargs = {\n",
        "        'validation_data': validation_dataset,\n",
        "        'validation_steps': validation_steps,\n",
        "        'validation_freq': params.evaluation.epochs_between_evals,\n",
        "    }\n",
        "\n",
        "  history = model.fit(\n",
        "      train_dataset,\n",
        "      epochs=train_epochs,\n",
        "      steps_per_epoch=train_steps,\n",
        "      initial_epoch=initial_epoch,\n",
        "      callbacks=callbacks,\n",
        "      **validation_kwargs)\n",
        "\n",
        "  validation_output = None\n",
        "  if not params.evaluation.skip_eval:\n",
        "    validation_output = model.evaluate(\n",
        "        validation_dataset, steps=validation_steps, verbose=2)\n",
        "\n",
        "  stats = common.build_stats(history,\n",
        "                             validation_output,\n",
        "                             callbacks)\n",
        "  return stats\n",
        "\n",
        "classifier_trainer.train_and_eval = train_and_eval\n",
        "classifier_trainer._get_metrics = _get_metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NC8Nuy-hLAw-",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "b0319a9b-2a39-4685-a375-d80139307ede",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%%writefile config.yaml\n",
        "\n",
        "# Training configuration for EfficientNet \n",
        "runtime:\n",
        "  model_dir: null\n",
        "  mode: 'train_and_eval'\n",
        "  distribution_strategy: 'tpu'\n",
        "  run_eagerly: False\n",
        "  enable_xla: True\n",
        "train_dataset:\n",
        "  name: 'imagenet2012'\n",
        "  data_dir: null\n",
        "  builder: 'records'\n",
        "  split: 'train'\n",
        "  one_hot: False\n",
        "  num_classes: 2\n",
        "  # num_examples: 26488\n",
        "  num_examples: 46648\n",
        "  image_size: 512\n",
        "  batch_size: 32\n",
        "  use_per_replica_batch_size: True\n",
        "  dtype: 'bfloat16'\n",
        "  augmenter:\n",
        "    name: 'autoaugment'\n",
        "validation_dataset:\n",
        "  name: 'imagenet2012'\n",
        "  data_dir: null\n",
        "  builder: 'records'\n",
        "  split: 'validation'\n",
        "  cache: True\n",
        "  one_hot: False\n",
        "  num_classes: 2\n",
        "  # num_examples: 6638\n",
        "  num_examples: 11809\n",
        "  image_size: 512\n",
        "  batch_size: 64\n",
        "  use_per_replica_batch_size: True\n",
        "  dtype: 'bfloat16'\n",
        "model:\n",
        "  model_params:\n",
        "    model_name: 'efficientnet-b3'\n",
        "    model_weights_path: 'gs://recursion-kaggle/melanoma/efficientnet_b3_feature-vector'\n",
        "    overrides:\n",
        "      num_classes: 2\n",
        "      batch_norm: 'tpu'\n",
        "      dtype: 'bfloat16'\n",
        "      # dropout_rate: 0.0\n",
        "  optimizer:\n",
        "    # RMSProp\n",
        "    # name: 'rmsprop'\n",
        "    # momentum: 0.9\n",
        "    # decay: 0.9\n",
        "\n",
        "    # AdamW\n",
        "    name: 'adam'\n",
        "    beta_1: 0.9\n",
        "    beta_2: 0.999\n",
        "    epsilon: 0.0000001\n",
        "    moving_average_decay: 0.0\n",
        "    # decay: 0.9\n",
        "    # lookahead: True\n",
        "\n",
        "  learning_rate:\n",
        "    # boundaries: None\n",
        "    # decay_epochs: 2.4\n",
        "    # decay_rate: 0.8\n",
        "    initial_lr: 0.001\n",
        "    name: 'exponential'\n",
        "    # scale_by_batch_size: 0.0078125\n",
        "    warmup_epochs: 5\n",
        "  loss:\n",
        "    label_smoothing: 0.0\n",
        "  num_classes: 2\n",
        "train:\n",
        "  resume_checkpoint: False\n",
        "  epochs: 50\n",
        "  metrics: ['auc']\n",
        "  callbacks:\n",
        "    enable_checkpoint_and_export: True\n",
        "    enable_tensorboard: False\n",
        "evaluation:\n",
        "  epochs_between_evals: 1"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting config.yaml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLhfRddSUXaA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from absl import app\n",
        "from absl import flags"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adDNu22qVFQd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "define_classifier_flags()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Luw25khrRxZG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "cellView": "form",
        "outputId": "ef00ee90-49c7-4565-a728-fd0a26859d21"
      },
      "source": [
        "#@title Train\n",
        "logging.set_verbosity(logging.INFO)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  if '-f' in sys.argv:\n",
        "    sys.argv.remove('-f')\n",
        "  flags.FLAGS.mode = 'train_and_eval' \n",
        "  flags.FLAGS.model_type = 'efficientnet' \n",
        "  flags.FLAGS.dataset = 'imagenet' \n",
        "  flags.FLAGS.tpu = TPU_NAME \n",
        "  flags.FLAGS.model_dir = 'gs://recursion-kaggle/melanoma/models/model_b3_test' #@param {type:\"string\"}\n",
        "  flags.FLAGS.data_dir = 'gs://recursion-kaggle/melanoma/stratified_ex/fold0' #@param {type:\"string\"}\n",
        "  flags.FLAGS.config_file = 'config.yaml' #@param {type:\"string\"}\n",
        "\n",
        "  app.run(main)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I0610 22:49:28.845302 140176018913152 classifier_trainer.py:185] Base params: {'evaluation': {'epochs_between_evals': 1, 'skip_eval': False, 'steps': None},\n",
            " 'export': {'checkpoint': None, 'destination': None},\n",
            " 'mode': None,\n",
            " 'model': {'learning_rate': {'boundaries': None,\n",
            "                             'decay_epochs': 2.4,\n",
            "                             'decay_rate': 0.97,\n",
            "                             'examples_per_epoch': None,\n",
            "                             'initial_lr': 0.008,\n",
            "                             'multipliers': None,\n",
            "                             'name': 'exponential',\n",
            "                             'scale_by_batch_size': 0.0078125,\n",
            "                             'warmup_epochs': 5},\n",
            "           'loss': {'label_smoothing': 0.1,\n",
            "                    'loss_scale': None,\n",
            "                    'name': 'categorical_crossentropy'},\n",
            "           'model_params': {'copy_to_local': False,\n",
            "                            'model_name': 'efficientnet-b0',\n",
            "                            'model_weights_path': '',\n",
            "                            'overrides': {'batch_norm': 'default',\n",
            "                                          'num_classes': 1000,\n",
            "                                          'rescale_input': True}},\n",
            "           'name': 'EfficientNet',\n",
            "           'num_classes': 1000,\n",
            "           'optimizer': {'beta_1': None,\n",
            "                         'beta_2': None,\n",
            "                         'decay': 0.9,\n",
            "                         'epsilon': 0.001,\n",
            "                         'lookahead': None,\n",
            "                         'momentum': 0.9,\n",
            "                         'moving_average_decay': None,\n",
            "                         'name': 'rmsprop',\n",
            "                         'nesterov': None}},\n",
            " 'model_dir': None,\n",
            " 'model_name': None,\n",
            " 'runtime': {'all_reduce_alg': None,\n",
            "             'dataset_num_private_threads': None,\n",
            "             'distribution_strategy': 'mirrored',\n",
            "             'enable_xla': False,\n",
            "             'gpu_thread_mode': None,\n",
            "             'gpu_threads_enabled': False,\n",
            "             'loss_scale': None,\n",
            "             'num_gpus': 0,\n",
            "             'num_packs': 1,\n",
            "             'per_gpu_thread_count': 0,\n",
            "             'run_eagerly': False,\n",
            "             'task_index': -1,\n",
            "             'tpu': None,\n",
            "             'worker_hosts': None},\n",
            " 'train': {'callbacks': {'enable_checkpoint_and_export': True,\n",
            "                         'enable_tensorboard': True,\n",
            "                         'enable_time_history': True},\n",
            "           'epochs': 500,\n",
            "           'metrics': ['accuracy', 'top_5'],\n",
            "           'resume_checkpoint': True,\n",
            "           'steps': None,\n",
            "           'tensorboard': {'track_lr': True, 'write_model_weights': False},\n",
            "           'time_history': {'log_steps': 100}},\n",
            " 'train_dataset': {'augmenter': {'name': None, 'params': None},\n",
            "                   'batch_size': 128,\n",
            "                   'builder': 'records',\n",
            "                   'cache': False,\n",
            "                   'data_dir': None,\n",
            "                   'deterministic_train': False,\n",
            "                   'download': False,\n",
            "                   'dtype': 'float32',\n",
            "                   'file_shuffle_buffer_size': 1024,\n",
            "                   'filenames': None,\n",
            "                   'image_size': 224,\n",
            "                   'mean_subtract': False,\n",
            "                   'name': 'imagenet2012',\n",
            "                   'num_channels': 'infer',\n",
            "                   'num_classes': 'infer',\n",
            "                   'num_devices': 1,\n",
            "                   'num_examples': 'infer',\n",
            "                   'one_hot': True,\n",
            "                   'shuffle_buffer_size': 10000,\n",
            "                   'skip_decoding': True,\n",
            "                   'split': 'train',\n",
            "                   'standardize': False,\n",
            "                   'use_per_replica_batch_size': True,\n",
            "                   'use_slack': True},\n",
            " 'validation_dataset': {'augmenter': {'name': None, 'params': None},\n",
            "                        'batch_size': 128,\n",
            "                        'builder': 'records',\n",
            "                        'cache': False,\n",
            "                        'data_dir': None,\n",
            "                        'deterministic_train': False,\n",
            "                        'download': False,\n",
            "                        'dtype': 'float32',\n",
            "                        'file_shuffle_buffer_size': 1024,\n",
            "                        'filenames': None,\n",
            "                        'image_size': 224,\n",
            "                        'mean_subtract': False,\n",
            "                        'name': 'imagenet2012',\n",
            "                        'num_channels': 'infer',\n",
            "                        'num_classes': 'infer',\n",
            "                        'num_devices': 1,\n",
            "                        'num_examples': 'infer',\n",
            "                        'one_hot': True,\n",
            "                        'shuffle_buffer_size': 10000,\n",
            "                        'skip_decoding': True,\n",
            "                        'split': 'validation',\n",
            "                        'standardize': False,\n",
            "                        'use_per_replica_batch_size': True,\n",
            "                        'use_slack': True}}\n",
            "I0610 22:49:28.846317 140176018913152 classifier_trainer.py:188] Overriding params: config.yaml\n",
            "I0610 22:49:28.855913 140176018913152 classifier_trainer.py:188] Overriding params: None\n",
            "I0610 22:49:28.856759 140176018913152 classifier_trainer.py:188] Overriding params: {'model_dir': 'gs://recursion-kaggle/melanoma/models/model_b3_test', 'mode': 'train_and_eval', 'model': {'name': 'efficientnet'}, 'runtime': {'run_eagerly': None, 'tpu': 'grpc://10.49.17.50:8470'}, 'train_dataset': {'data_dir': 'gs://recursion-kaggle/melanoma/stratified_ex/fold0'}, 'validation_dataset': {'data_dir': 'gs://recursion-kaggle/melanoma/stratified_ex/fold0'}, 'train': {'time_history': {'log_steps': 100}}}\n",
            "I0610 22:49:28.859318 140176018913152 classifier_trainer.py:195] Final model parameters: {'evaluation': {'epochs_between_evals': 1, 'skip_eval': False, 'steps': None},\n",
            " 'export': {'checkpoint': None, 'destination': None},\n",
            " 'mode': 'train_and_eval',\n",
            " 'model': {'learning_rate': {'boundaries': None,\n",
            "                             'decay_epochs': 2.4,\n",
            "                             'decay_rate': 0.97,\n",
            "                             'examples_per_epoch': None,\n",
            "                             'initial_lr': 0.001,\n",
            "                             'multipliers': None,\n",
            "                             'name': 'exponential',\n",
            "                             'scale_by_batch_size': 0.0078125,\n",
            "                             'warmup_epochs': 5},\n",
            "           'loss': {'label_smoothing': 0.0,\n",
            "                    'loss_scale': None,\n",
            "                    'name': 'categorical_crossentropy'},\n",
            "           'model_params': {'copy_to_local': False,\n",
            "                            'model_name': 'efficientnet-b3',\n",
            "                            'model_weights_path': 'gs://recursion-kaggle/melanoma/efficientnet_b3_feature-vector',\n",
            "                            'overrides': {'batch_norm': 'tpu',\n",
            "                                          'dtype': 'bfloat16',\n",
            "                                          'num_classes': 2,\n",
            "                                          'rescale_input': True}},\n",
            "           'name': 'efficientnet',\n",
            "           'num_classes': 2,\n",
            "           'optimizer': {'beta_1': 0.9,\n",
            "                         'beta_2': 0.999,\n",
            "                         'decay': 0.9,\n",
            "                         'epsilon': 1e-07,\n",
            "                         'lookahead': None,\n",
            "                         'momentum': 0.9,\n",
            "                         'moving_average_decay': 0.0,\n",
            "                         'name': 'adam',\n",
            "                         'nesterov': None}},\n",
            " 'model_dir': 'gs://recursion-kaggle/melanoma/models/model_b3_test',\n",
            " 'model_name': None,\n",
            " 'runtime': {'all_reduce_alg': None,\n",
            "             'dataset_num_private_threads': None,\n",
            "             'distribution_strategy': 'tpu',\n",
            "             'enable_xla': True,\n",
            "             'gpu_thread_mode': None,\n",
            "             'gpu_threads_enabled': False,\n",
            "             'loss_scale': None,\n",
            "             'mode': 'train_and_eval',\n",
            "             'model_dir': None,\n",
            "             'num_gpus': 0,\n",
            "             'num_packs': 1,\n",
            "             'per_gpu_thread_count': 0,\n",
            "             'run_eagerly': None,\n",
            "             'task_index': -1,\n",
            "             'tpu': 'grpc://10.49.17.50:8470',\n",
            "             'worker_hosts': None},\n",
            " 'train': {'callbacks': {'enable_checkpoint_and_export': True,\n",
            "                         'enable_tensorboard': False,\n",
            "                         'enable_time_history': True},\n",
            "           'epochs': 50,\n",
            "           'metrics': ['auc'],\n",
            "           'resume_checkpoint': False,\n",
            "           'steps': None,\n",
            "           'tensorboard': {'track_lr': True, 'write_model_weights': False},\n",
            "           'time_history': {'log_steps': 100}},\n",
            " 'train_dataset': {'augmenter': {'name': 'autoaugment', 'params': None},\n",
            "                   'batch_size': 32,\n",
            "                   'builder': 'records',\n",
            "                   'cache': False,\n",
            "                   'data_dir': 'gs://recursion-kaggle/melanoma/stratified_ex/fold0',\n",
            "                   'deterministic_train': False,\n",
            "                   'download': False,\n",
            "                   'dtype': 'bfloat16',\n",
            "                   'file_shuffle_buffer_size': 1024,\n",
            "                   'filenames': None,\n",
            "                   'image_size': 512,\n",
            "                   'mean_subtract': False,\n",
            "                   'name': 'imagenet2012',\n",
            "                   'num_channels': 'infer',\n",
            "                   'num_classes': 2,\n",
            "                   'num_devices': 1,\n",
            "                   'num_examples': 46648,\n",
            "                   'one_hot': False,\n",
            "                   'shuffle_buffer_size': 10000,\n",
            "                   'skip_decoding': True,\n",
            "                   'split': 'train',\n",
            "                   'standardize': False,\n",
            "                   'use_per_replica_batch_size': True,\n",
            "                   'use_slack': True},\n",
            " 'validation_dataset': {'augmenter': {'name': None, 'params': None},\n",
            "                        'batch_size': 64,\n",
            "                        'builder': 'records',\n",
            "                        'cache': True,\n",
            "                        'data_dir': 'gs://recursion-kaggle/melanoma/stratified_ex/fold0',\n",
            "                        'deterministic_train': False,\n",
            "                        'download': False,\n",
            "                        'dtype': 'bfloat16',\n",
            "                        'file_shuffle_buffer_size': 1024,\n",
            "                        'filenames': None,\n",
            "                        'image_size': 512,\n",
            "                        'mean_subtract': False,\n",
            "                        'name': 'imagenet2012',\n",
            "                        'num_channels': 'infer',\n",
            "                        'num_classes': 2,\n",
            "                        'num_devices': 1,\n",
            "                        'num_examples': 11809,\n",
            "                        'one_hot': False,\n",
            "                        'shuffle_buffer_size': 10000,\n",
            "                        'skip_decoding': True,\n",
            "                        'split': 'validation',\n",
            "                        'standardize': False,\n",
            "                        'use_per_replica_batch_size': True,\n",
            "                        'use_slack': True}}\n",
            "I0610 22:49:28.860045 140176018913152 <ipython-input-21-fbb1333ce392>:56] Running train and eval.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.49.17.50:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0610 22:49:28.869886 140176018913152 tpu_strategy_util.py:70] TPU system grpc://10.49.17.50:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.49.17.50:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0610 22:49:28.871539 140176018913152 tpu_strategy_util.py:72] Initializing the TPU system: grpc://10.49.17.50:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0610 22:49:28.878490 140176018913152 tpu_strategy_util.py:100] Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0610 22:49:43.313759 140176018913152 tpu_strategy_util.py:123] Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0610 22:49:43.317687 140176018913152 tpu_system_metadata.py:140] Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0610 22:49:43.318791 140176018913152 tpu_system_metadata.py:141] *** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0610 22:49:43.319834 140176018913152 tpu_system_metadata.py:142] *** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0610 22:49:43.320794 140176018913152 tpu_system_metadata.py:144] *** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0610 22:49:43.321694 140176018913152 tpu_system_metadata.py:146] *** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0610 22:49:43.322565 140176018913152 tpu_system_metadata.py:146] *** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0610 22:49:43.323482 140176018913152 tpu_system_metadata.py:146] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0610 22:49:43.324476 140176018913152 tpu_system_metadata.py:146] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0610 22:49:43.325515 140176018913152 tpu_system_metadata.py:146] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0610 22:49:43.328333 140176018913152 tpu_system_metadata.py:146] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0610 22:49:43.329218 140176018913152 tpu_system_metadata.py:146] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0610 22:49:43.330089 140176018913152 tpu_system_metadata.py:146] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0610 22:49:43.330990 140176018913152 tpu_system_metadata.py:146] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0610 22:49:43.331817 140176018913152 tpu_system_metadata.py:146] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0610 22:49:43.332592 140176018913152 tpu_system_metadata.py:146] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0610 22:49:43.333533 140176018913152 tpu_system_metadata.py:146] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0610 22:49:43.334408 140176018913152 tpu_system_metadata.py:146] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
            "I0610 22:49:43.335729 140176018913152 <ipython-input-21-fbb1333ce392>:68] Detected 8 devices.\n",
            "W0610 22:49:43.336300 140176018913152 classifier_trainer.py:109] label_smoothing not applied, so datasets will not be one hot encoded.\n",
            "I0610 22:49:43.337088 140176018913152 dataset_factory.py:174] Using augmentation: autoaugment\n",
            "I0610 22:49:43.337967 140176018913152 dataset_factory.py:174] Using augmentation: None\n",
            "I0610 22:49:43.338646 140176018913152 <ipython-input-17-254e7a04ba02>:20] Using TFRecords to load data.\n",
            "I0610 22:49:47.609058 140176018913152 <ipython-input-17-254e7a04ba02>:20] Using TFRecords to load data.\n",
            "I0610 22:49:47.686149 140176018913152 dataset_builder.py:202] Load pre-computed datasetinfo (eg: splits) from bucket.\n",
            "I0610 22:49:47.689069 140176018913152 dataset_info.py:431] Loading info from GCS for imagenet2012/5.0.0\n",
            "I0610 22:49:47.713917 140176018913152 dataset_info.py:403] Field info.description from disk and from code do not match. Keeping the one from code.\n",
            "I0610 22:49:47.750488 140176018913152 <ipython-input-21-fbb1333ce392>:86] Global batch size: 256\n",
            "I0610 22:49:47.768326 140176018913152 efficientnet_model.py:146] round_filter input=32 output=40\n",
            "I0610 22:49:48.051702 140176018913152 efficientnet_model.py:146] round_filter input=32 output=40\n",
            "I0610 22:49:48.052754 140176018913152 efficientnet_model.py:146] round_filter input=16 output=24\n",
            "I0610 22:49:49.326554 140176018913152 efficientnet_model.py:146] round_filter input=16 output=24\n",
            "I0610 22:49:49.327676 140176018913152 efficientnet_model.py:146] round_filter input=24 output=32\n",
            "I0610 22:49:51.865675 140176018913152 efficientnet_model.py:146] round_filter input=24 output=32\n",
            "I0610 22:49:51.866752 140176018913152 efficientnet_model.py:146] round_filter input=40 output=48\n",
            "I0610 22:49:54.431470 140176018913152 efficientnet_model.py:146] round_filter input=40 output=48\n",
            "I0610 22:49:54.432458 140176018913152 efficientnet_model.py:146] round_filter input=80 output=96\n",
            "I0610 22:49:59.743232 140176018913152 efficientnet_model.py:146] round_filter input=80 output=96\n",
            "I0610 22:49:59.744373 140176018913152 efficientnet_model.py:146] round_filter input=112 output=136\n",
            "I0610 22:50:03.928642 140176018913152 efficientnet_model.py:146] round_filter input=112 output=136\n",
            "I0610 22:50:03.929606 140176018913152 efficientnet_model.py:146] round_filter input=192 output=232\n",
            "I0610 22:50:09.088313 140176018913152 efficientnet_model.py:146] round_filter input=192 output=232\n",
            "I0610 22:50:09.089358 140176018913152 efficientnet_model.py:146] round_filter input=320 output=384\n",
            "I0610 22:50:10.798429 140176018913152 efficientnet_model.py:146] round_filter input=1280 output=1536\n",
            "I0610 22:50:11.109372 140176018913152 <ipython-input-26-f6ad56193700>:46] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='tpu', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=2, model_name='efficientnet', rescale_input=True, data_format='channels_last', dtype='bfloat16')\n",
            "I0610 22:51:08.662449 140176018913152 optimizer_factory.py:133] Scaling the learning rate based on the batch size multiplier. New base_lr: 0.002000\n",
            "I0610 22:51:08.663672 140176018913152 optimizer_factory.py:138] Using exponential learning rate with: initial_learning_rate: 0.002000, decay_steps: 436, decay_rate: 0.970000\n",
            "I0610 22:51:08.664344 140176018913152 optimizer_factory.py:159] Applying 910 warmup steps to the learning rate\n",
            "I0610 22:51:08.665004 140176018913152 optimizer_factory.py:53] Building adam optimizer with params {'name': 'adam', 'decay': 0.9, 'epsilon': 1e-07, 'momentum': 0.9, 'nesterov': None, 'moving_average_decay': 0.0, 'lookahead': None, 'beta_1': 0.9, 'beta_2': 0.999}\n",
            "I0610 22:51:08.665493 140176018913152 optimizer_factory.py:76] Using Adam\n",
            "I0610 22:51:08.821313 140176018913152 classifier_trainer.py:292] Saving experiment configuration to gs://recursion-kaggle/melanoma/models/model_b3_test/params.yaml\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "182/182 [==============================] - ETA: 0s - auc: 0.6953 - loss: 0.6525\n",
            "Epoch 00001: val_auc improved from -inf to 0.85723, saving model to gs://recursion-kaggle/melanoma/models/model_b3_test/model.ckpt\n",
            "182/182 [==============================] - 206s 1s/step - auc: 0.6953 - loss: 0.6525 - val_auc: 0.8564 - val_loss: 0.2831\n",
            "Epoch 2/50\n",
            " 58/182 [========>.....................] - ETA: 2:50 - auc: 0.7650 - loss: 0.3587"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlWW1zp2YV98",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}